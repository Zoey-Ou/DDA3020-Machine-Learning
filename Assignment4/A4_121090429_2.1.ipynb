{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7266e3e7",
   "metadata": {},
   "source": [
    "## DDA3020 Autumn 2023 Homework 4\n",
    "\n",
    "### Programming Task 2.1\n",
    "\n",
    "#### student ID: 121090429\n",
    "#### Name: Ou Ziyi\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e82c2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(55)  # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae4b28",
   "metadata": {},
   "source": [
    "## 1. Two clustering algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e17bcb",
   "metadata": {},
   "source": [
    "### (1) K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "547bdb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, n_clusters, max_iters=100):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iters = max_iters\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize centroids randomly\n",
    "        centroids = X[np.random.choice(n_samples, self.n_clusters, replace=False)]\n",
    "        \n",
    "        for _ in range(self.max_iters):\n",
    "            # Assign each point to the nearest centroid\n",
    "            labels = np.argmin(np.linalg.norm(X[:, np.newaxis] - centroids, axis=2), axis=1)\n",
    "            \n",
    "            # Update centroids\n",
    "            new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(self.n_clusters)])\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.all(centroids == new_centroids):\n",
    "                break\n",
    "            \n",
    "            centroids = new_centroids\n",
    "\n",
    "        self.centroids = centroids\n",
    "        self.labels = labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a5eb84",
   "metadata": {},
   "source": [
    "### (2) GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8c028b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class GMM:\n",
    "    def __init__(self, n_components, max_iters=100,allow_singular=True):\n",
    "        self.n_components = n_components\n",
    "        self.max_iters = max_iters\n",
    "        self.weights = None\n",
    "        self.means = None\n",
    "        self.covariances = None\n",
    "        self.labels = None  # Add labels attribute\n",
    "        self.allow_singular = allow_singular\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.weights = np.ones(self.n_components) / self.n_components\n",
    "        self.means = X[np.random.choice(n_samples, self.n_components, replace=False)]\n",
    "        self.covariances = [np.cov(X.T) for _ in range(self.n_components)]\n",
    "\n",
    "        for _ in range(self.max_iters):\n",
    "            # Expectation step\n",
    "            responsibilities = np.array([self.weights[i] * multivariate_normal.pdf(X, self.means[i], self.covariances[i]) for i in range(self.n_components)]).T\n",
    "            responsibilities /= responsibilities.sum(axis=1, keepdims=True)\n",
    "\n",
    "            # Maximization step\n",
    "            Nk = responsibilities.sum(axis=0)\n",
    "            self.weights = Nk / n_samples\n",
    "            self.means = np.dot(responsibilities.T, X) / Nk[:, np.newaxis]\n",
    "            self.covariances = [np.dot((X - self.means[i]).T, responsibilities[:, i][:, np.newaxis] * (X - self.means[i])) / Nk[i] for i in range(self.n_components)]\n",
    "\n",
    "        # Assign labels based on the probability distribution\n",
    "        self.labels = np.argmax(responsibilities, axis=1)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        responsibilities = np.array([self.weights[i] * multivariate_normal.pdf(X, self.means[i], self.covariances[i]) for i in range(self.n_components)]).T\n",
    "        responsibilities /= responsibilities.sum(axis=1, keepdims=True)\n",
    "        return responsibilities\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f20cec",
   "metadata": {},
   "source": [
    "## 2. Three evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ac86a",
   "metadata": {},
   "source": [
    "### (1) Silhouette Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0012ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def silhouette_coefficient(X, labels):\n",
    "    n_samples = len(X)\n",
    "    a = np.zeros(n_samples)\n",
    "    b = np.zeros(n_samples)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        cluster_i = labels[i]\n",
    "        cluster_i_points = X[labels == cluster_i]\n",
    "        a[i] = np.mean(np.linalg.norm(X[i] - cluster_i_points, axis=1))\n",
    "\n",
    "        other_clusters = [j for j in range(len(np.unique(labels))) if j != cluster_i]\n",
    "        min_distances = np.zeros(len(other_clusters))\n",
    "\n",
    "        for idx, cluster_j in enumerate(other_clusters):\n",
    "            cluster_j_points = X[labels == cluster_j]\n",
    "            min_distances[idx] = np.mean(np.linalg.norm(X[i] - cluster_j_points, axis=1))\n",
    "\n",
    "        b[i] = np.min(min_distances)\n",
    "\n",
    "    s = (b - a) / np.maximum(a, b)\n",
    "    return np.mean(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c6d994",
   "metadata": {},
   "source": [
    "### (2) Rand Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ba3294cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_index(true_labels, pred_labels):\n",
    "    n = len(true_labels)\n",
    "    a, b = 0, 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            same_true = true_labels[i] == true_labels[j]\n",
    "            same_pred = pred_labels[i] == pred_labels[j]\n",
    "\n",
    "            if same_true and same_pred:\n",
    "                a += 1\n",
    "            elif not same_true and not same_pred:\n",
    "                b += 1\n",
    "\n",
    "    # Rand Index = (a + b) / C(n, 2)\n",
    "    return (a + b) / (n * (n - 1) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c3c419",
   "metadata": {},
   "source": [
    "### (3) Normalized Mutual Information (NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "28627c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMI(true_labels, pred_labels):\n",
    "    def entropy(labels):\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        probabilities = counts / len(labels)\n",
    "        return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "    # Mutual Information\n",
    "    h_true = entropy(true_labels)\n",
    "    h_pred = entropy(pred_labels)\n",
    "    h_joint = entropy(np.vstack((true_labels, pred_labels)).T)\n",
    "\n",
    "    mi = h_true + h_pred - h_joint\n",
    "\n",
    "    # Normalized Mutual Information\n",
    "    nmi = mi / np.sqrt(h_true * h_pred)\n",
    "    return nmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ac71d",
   "metadata": {},
   "source": [
    "## 3. Apply clustering algorithm to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "778c9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "import pandas as pd\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "seeds = pd.read_csv(os.path.join(current_directory,'seeds.csv'), header=0)\n",
    "seeds_features = seeds.iloc[:, :-1]\n",
    "seeds_true_label = seeds.iloc[:, -1]\n",
    "\n",
    "vowel = pd.read_csv(os.path.join(current_directory,'Vowel.csv'), header=0)\n",
    "vowel_features = vowel.iloc[:, :-1]\n",
    "vowel_true_label = vowel.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b54e5",
   "metadata": {},
   "source": [
    "### 3.1 seeds: Clustering algorithm & evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "93d457f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for seeds dataset:\n",
      "Number of clusters (k): 2\n",
      "K-means Silhouette Coefficient: 0.5228955002005705\n",
      "K-means Rand Index: 0.7309637730690363\n",
      "K-means NMI: 0.7074384585185741\n",
      "GMM Silhouette Coefficient: 0.45861106387924744\n",
      "GMM Rand Index: 0.73734335839599\n",
      "GMM NMI: 0.5926542996750351\n",
      "\n",
      "Results for seeds dataset:\n",
      "Number of clusters (k): 3\n",
      "K-means Silhouette Coefficient: 0.47943599429227485\n",
      "K-means Rand Index: 0.8743677375256322\n",
      "K-means NMI: 0.8205373603161036\n",
      "GMM Silhouette Coefficient: 0.38082934469644125\n",
      "GMM Rand Index: 0.8621553884711779\n",
      "GMM NMI: 0.8500556625658585\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3]:\n",
    "    # K-means\n",
    "    kmeans_seeds = KMeans(n_clusters=i)\n",
    "    kmeans_seeds.fit(seeds_features.values)\n",
    "\n",
    "    silhouette_seeds_kmeans = silhouette_coefficient(seeds_features.values, kmeans_seeds.labels)\n",
    "    rand_index_seeds_kmeans = rand_index(seeds_true_label.values, kmeans_seeds.labels)\n",
    "    nmi_seeds_kmeans = NMI(seeds_true_label.values, kmeans_seeds.labels)\n",
    "    \n",
    "    # GMM\n",
    "    gmm_seeds = GMM(n_components=i)\n",
    "    gmm_seeds.fit(seeds_features.values)\n",
    "\n",
    "    silhouette_seeds_gmm = silhouette_coefficient(seeds_features.values, gmm_seeds.labels)\n",
    "    rand_index_seeds_gmm = rand_index(seeds_true_label.values, gmm_seeds.labels)\n",
    "    nmi_seeds_gmm = NMI(seeds_true_label.values, gmm_seeds.labels)\n",
    "    \n",
    "    # print results\n",
    "    print(\"\\nResults for seeds dataset:\")\n",
    "    print(\"Number of clusters (k):\", i)\n",
    "    print(\"K-means Silhouette Coefficient:\", silhouette_seeds_kmeans)\n",
    "    print(\"K-means Rand Index:\", rand_index_seeds_kmeans)\n",
    "    print(\"K-means NMI:\", nmi_seeds_kmeans)\n",
    "    print(\"GMM Silhouette Coefficient:\", silhouette_seeds_gmm)\n",
    "    print(\"GMM Rand Index:\", rand_index_seeds_gmm)\n",
    "    print(\"GMM NMI:\", nmi_seeds_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12044e",
   "metadata": {},
   "source": [
    "### 3.2 Vowel: Clustering algorithm & evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "38794f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 2\n",
      "K-means Silhouette Coefficient: 0.4915868678690223\n",
      "K-means Rand Index: 0.49767441860465117\n",
      "K-means NMI: 0.39392317145655925\n",
      "GMM Silhouette Coefficient: 0.06372575009670514\n",
      "GMM Rand Index: 0.508604753296361\n",
      "GMM NMI: 0.3958554866794623\n",
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 3\n",
      "K-means Silhouette Coefficient: 0.37996891703580543\n",
      "K-means Rand Index: 0.6287158746208291\n",
      "K-means NMI: 0.40813945125756407\n",
      "GMM Silhouette Coefficient: -0.03528727304452447\n",
      "GMM Rand Index: 0.6347764806814352\n",
      "GMM NMI: 0.41049244486503367\n",
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 4\n",
      "K-means Silhouette Coefficient: 0.3113853454986848\n",
      "K-means Rand Index: 0.6942366026289181\n",
      "K-means NMI: 0.4340348911844581\n",
      "GMM Silhouette Coefficient: 0.008319179391817604\n",
      "GMM Rand Index: 0.7199701769974773\n",
      "GMM NMI: 0.4340806838781665\n",
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 5\n",
      "K-means Silhouette Coefficient: 0.2893539431868894\n",
      "K-means Rand Index: 0.7387831806436458\n",
      "K-means NMI: 0.4594306234010669\n",
      "GMM Silhouette Coefficient: -0.014927853537388822\n",
      "GMM Rand Index: 0.7358703312191684\n",
      "GMM NMI: 0.45635206771865916\n",
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 6\n",
      "K-means Silhouette Coefficient: 0.2506417554748209\n",
      "K-means Rand Index: 0.770918487197557\n",
      "K-means NMI: 0.4837234811921347\n",
      "GMM Silhouette Coefficient: -0.030652183041551324\n",
      "GMM Rand Index: 0.7786214010683171\n",
      "GMM NMI: 0.48072240782718323\n",
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 7\n",
      "K-means Silhouette Coefficient: 0.2490867046730117\n",
      "K-means Rand Index: 0.7831908570027882\n",
      "K-means NMI: 0.5026274058809428\n",
      "GMM Silhouette Coefficient: -0.0497700222175391\n",
      "GMM Rand Index: 0.7893556393050832\n",
      "GMM NMI: 0.49596648223822576\n",
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 8\n",
      "K-means Silhouette Coefficient: 0.2584850302115469\n",
      "K-means Rand Index: 0.7924768412129383\n",
      "K-means NMI: 0.519446788298786\n",
      "GMM Silhouette Coefficient: -0.08508056547930776\n",
      "GMM Rand Index: 0.8193522688972639\n",
      "GMM NMI: 0.5244125996968391\n",
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 9\n",
      "K-means Silhouette Coefficient: 0.22585185033317137\n",
      "K-means Rand Index: 0.8008742633616244\n",
      "K-means NMI: 0.5356250707676012\n",
      "GMM Silhouette Coefficient: -0.10215056916103378\n",
      "GMM Rand Index: 0.8268141475421557\n",
      "GMM NMI: 0.5410960036368276\n",
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 10\n",
      "K-means Silhouette Coefficient: 0.22783203908540445\n",
      "K-means Rand Index: 0.8200120517612934\n",
      "K-means NMI: 0.556851198163493\n",
      "GMM Silhouette Coefficient: -0.08502835379115095\n",
      "GMM Rand Index: 0.8205022928986528\n",
      "GMM NMI: 0.5512506100250566\n",
      "\n",
      "Results for Vowel dataset:\n",
      "Number of clusters (k): 11\n",
      "K-means Silhouette Coefficient: 0.23359578403851497\n",
      "K-means Rand Index: 0.8148502211191797\n",
      "K-means NMI: 0.5636064902964609\n",
      "GMM Silhouette Coefficient: -0.1199064750833227\n",
      "GMM Rand Index: 0.8442994147746423\n",
      "GMM NMI: 0.5738716374400239\n"
     ]
    }
   ],
   "source": [
    "'''The class in the dataset Vowel is written in string, so we need to convert it into integer.'''\n",
    "def label_encoder(labels):   \n",
    "    unique_labels = np.unique(labels)\n",
    "    label_dict = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    return np.array([label_dict[label] for label in labels])\n",
    "\n",
    "for i in range(2,12):\n",
    "    # K-means\n",
    "    kmeans_vowel = KMeans(n_clusters=i)\n",
    "    kmeans_vowel.fit(vowel_features.values)\n",
    "    vowel_true_label_encoded = label_encoder(vowel_true_label.values)  # Convert string labels to integers\n",
    "\n",
    "    silhouette_vowel_kmeans = silhouette_coefficient(vowel_features.values, kmeans_vowel.labels)\n",
    "    rand_index_vowel_kmeans = rand_index(vowel_true_label.values, kmeans_vowel.labels)\n",
    "    nmi_vowel_kmeans = NMI(vowel_true_label_encoded, kmeans_vowel.labels)\n",
    "    \n",
    "    # GMM\n",
    "    gmm_vowel = GMM(n_components=i)\n",
    "    gmm_vowel.fit(vowel_features.values)\n",
    "    vowel_true_label_encoded = label_encoder(vowel_true_label.values)  # Convert string labels to integers\n",
    "\n",
    "    silhouette_vowel_gmm = silhouette_coefficient(vowel_features.values, gmm_vowel.labels)\n",
    "    rand_index_vowel_gmm = rand_index(vowel_true_label.values, gmm_vowel.labels)\n",
    "    nmi_vowel_gmm = NMI(vowel_true_label_encoded, gmm_vowel.labels)\n",
    "    \n",
    "    # print results\n",
    "    print(\"\\nResults for Vowel dataset:\")\n",
    "    print(\"Number of clusters (k):\", i)\n",
    "    print(\"K-means Silhouette Coefficient:\", silhouette_vowel_kmeans)\n",
    "    print(\"K-means Rand Index:\", rand_index_vowel_kmeans)\n",
    "    print(\"K-means NMI:\", nmi_vowel_kmeans)\n",
    "    print(\"GMM Silhouette Coefficient:\", silhouette_vowel_gmm)\n",
    "    print(\"GMM Rand Index:\", rand_index_vowel_gmm)\n",
    "    print(\"GMM NMI:\", nmi_vowel_gmm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
